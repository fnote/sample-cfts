AWSTemplateFormatVersion: 2010-09-09
Description: "Discount Service Data Populator"
Parameters:
  DatabasePassword:
    Type: String
    Description: Password of the database used for glue connection
    Default: ""
    NoEcho: true
  AvailabilityZoneForGlueConnection:
    Type: String
    Description: The Availability Zone of the glue connection
    Default: us-east-1b
    AllowedValues:
      - us-east-1a
      - us-east-1b
      - us-east-1c
      - us-east-1d
      - us-east-1e
      - us-east-1f
  SecurityGroupListForGlueConnction:
    Type: CommaDelimitedList
    Description: Security group list for glue connection
    Default: sg-06a4893b70fc2f68f
  SubnetIdForGlueConnection:
    Type: String
    Description: The subnetId to be referred
    Default: subnet-0ad1216eb31e15186
  IntermediateStorage:
    Description: S3 bucket name to store intermediate files
    Type: String
    Default: cp-discounts-etl-output-bucket-dev
  EnvironmentShort:
    Description: Environment for application
    Type: String
    Default: DEV
    AllowedValues:
      - DEV
      - QA
      - STG
      - EXE
      - TST
      - PROD
    ConstraintDescription: Must be a valid environment
  NotifierLambdaSecutyGroup:
    Description: The list of Securty groups to use the Cloud Pricing Notification Service Api
    Type: List<AWS::EC2::SecurityGroup::Id>
    Default: sg-014f39d2fd8370bf6
  NotifierLambdaSubnets:
    Type: List<AWS::EC2::Subnet::Id>
    Description: The list of Subnets to use the Cloud Pricing Notification Service Api
    Default: subnet-0a5d9eea71b9c97c6, subnet-0186b43162a344d9a, subnet-0ad1216eb31e15186
  NotificationURL:
    Type: String
    Description: Cloud pricing Notification service URL
    Default: https://vpce-0ee878fea3ffd19c4-6bsoxvze.execute-api.us-east-1.vpce.amazonaws.com/stg/v1/cpns/notifications
  NotificationHost:
    Type: String
    Description: Cloud Pricing Notification service host
    Default: ivsgfq5vdl.execute-api.us-east-1.amazonaws.com
  PONumber:
    Description: PO Number for billing
    Type: String
    Default: '7000002358'
    MinLength: '1'
    MaxLength: '255'
    AllowedPattern: "[\\x20-\\x7E]*"
    ConstraintDescription: Must contain only ASCII characters.
  ApplicationID:
    Description: Application ID - Official Application_ID, this is generated by Sysco's
      CMDB
    Type: String
    Default: APP-001151
    MinLength: '1'
    MaxLength: '255'
    AllowedPattern: "[\\x20-\\x7E]*"
    ConstraintDescription: Must contain only ASCII characters.
  ApplicationName:
    Description: Application_Name - Common, user-friendly name
    Type: String
    Default: Cloud Pricing
    MinLength: '1'
    MaxLength: '255'
    AllowedPattern: "[\\x20-\\x7E]*"
    ConstraintDescription: Must contain only ASCII characters.
  Approver:
    Description: Person approving instance funding.  This should be Email address
      formatted
    Type: String
    Default: villanueva.loi@corp.sysco.com
    MinLength: '1'
    MaxLength: '255'
  Owner:
    Description: Email address usually Product/ Platform Owner, though team distribution
      list for technical product/platform team contact
    Type: String
    Default: krishan.senevirathne@sysco.com
    MinLength: '1'
    MaxLength: '255'
  Component:
    Description: Component name
    Type: String
    Default: Discount Service
  SupportEmail:
    Description: Email distribution list for technical product/platform team contact
    Type: String
    Default: 000-BT-PricingPlatform@Corp.sysco.com
    MinLength: '1'
    MaxLength: '255'
  ProjectID:
    Description: Project_ID - BT Project ID for this workload
    Type: String
    Default: BT.001176
    MinLength: '1'
    MaxLength: '255'
    AllowedPattern: "[\\x20-\\x7E]*"
    ConstraintDescription: Must contain only ASCII characters.
  2WTAGGER:
    Description: Used by 2nd Watch Managed Services in shared accounts to determine
      if a resource is supported
    Type: String
    Default: team-managed
    MinLength: '1'
    MaxLength: '255'
    AllowedValues:
      - team-managed
      - adlm-managed
      - 2w-managed
    ConstraintDescription: Must contain only ASCII characters.
  Platform:
    Description: Platform
    Type: String
    Default: Cloud Pricing V4
  ValidationTypeCE:
    Description: Validation type soft or hard validation in CE flow
    Type: String
    Default: '{"CUSTOMER_ID":"False", "ITEM_ID" :"False","DISCOUNT_ID":"False","EFFECTIVE_DATE":"False","EXPIRATION_DATE":"False","EXPORT_DATE":"False","SEQUENCE_ID":"False","TEMPLATE_DISCOUNT":"False"}'
  ValidationTypeMDT:
    Description: Validation type soft or hard validation for each attribute in MDT flow
    Type: String
    Default: '{"DISCOUNT_ID":"False", "DISCOUNT_NAME" :"False","DISCOUNT_TYPE":"False","EFFECTIVE_DATE":"False","EXPIRATION_DATE":"False","EXPORT_DATE":"False","SEQUENCE_ID":"False","QUALIFICATION_MAGNITUDE":"False"}'
  ListOfDiscounts:
    Description: discount name list
    Type: String
    Default: 'NEW_CUSTOMER_DISCOUNT,CASE_VOLUME_DISCOUNT,CASE_SPLIT_UPCHARGE,STRATEGIC_RPA_DISCOUNT,NEW_ATTRIBUTE_GROUP_DISCOUNT'
  AllowedColumnsMDT:
    Description: Allowed column names in mdt file
    Type: String
    Default: 'DISCOUNT_ID,DISCOUNT_NAME,DISCOUNT_TYPE,QUALIFICATION_MAGNITUDE,EFFECTIVE_DATE,EXPIRATION_DATE,SEQUENCE_ID,EXPORT_DATE'
  CommonDBEndpointName:
    Description: Common DB Endpoint of discount service
    Type: String
    Default: cp-discounts-db-cluster-01-dev.cluster-c6xai0tt38eb.us-east-1.rds.amazonaws.com
  ActiveDBClusters:
    Description: Active database clusters of discount service
    Type: String
    Default: '01,02'
  EnableTwoClusters:
    Description: If two DB Clusters are there, set this to true
    Type: String
    Default: 'false'
    AllowedValues:
      - 'true'
      - 'false'
  GlueConnectionNamePlaceholder:
    Description: Placeholder name for the AWS Glue Connection
    Type: String
    Default: 'cp-DISCOUNTS-etl-connection-{}-cluster-{}'
  ETLMaximumConcurrency:
    Description: Maximum Concurrency Allowed for Discount ETL Step Functions
    Type: String
    Default: 5
  CELoadJobMaximumConcurrency:
    Description: Maximum Concurrency Allowed for CE load jobs
    Type: String
    Default: 4
  CELoadJobMaximumConcurrencyForCluster01:
    Description: Maximum allowed load job count for cluster 01
    Type: String
    Default: 2
  CELoadJobMaximumConcurrencyForCluster02:
    Description: Maximum allowed load job count for cluster 02
    Type: String
    Default: 2
  PartitionJobWorkerType:
    Description: AWS Glue worker type for Spark job
    Type: String
    Default: Standard
    AllowedValues:
      - Standard
      - G.1X
      - G.2X
  PartitionJobWorkerCountMin:
    Description: Minimum Worker Count for the Partition Job
    Type: String
    Default: 5
  PartitionJobWorkerCountMax:
    Description: Maximum Worker Count for the Partition Job
    Type: String
    Default: 50
  PartialLoadFileSizeUpperBound:
    Description: Upper bound value of customer eligibility partial load file size in GB
    Type: String
    Default: 0.5
  TeamsWebhookURL:
    Description: Microsoft teams webhook url for sending error notifications
    Type: String
    Default: 'https://sysco.webhook.office.com/webhookb2/333723ea-275d-4f46-bf5a-4591e9c67d25@b7aa4308-bf33-414f-9971-6e0c972cbe5d/IncomingWebhook/8e0849f59e584d1ab5c37194ed5a7f4c/b8228f9c-e316-4869-a733-e7af23d9f1e3'

Conditions:
  twoClustersEnabled: !Equals
    - !Ref EnableTwoClusters
    -
      -
    - 'true'

Mappings:
  EnvMap:
    DEV:
      val: dev
      name: Development
    QA:
      val: qa
      name: Quality
    STG:
      val: stg
      name: Staging
    EXE:
      val: exe
      name: Execution
    TST:
      val: tst
      name: Tuning
    PROD:
      val: prod
      name: Production

Resources:
  MDTDataStorage:
    DependsOn: MDTLambdaInvokePermission
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub
        - 'cp-discounts-etl-mdt-data-storage-${env}'
        - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:*
            Function: !GetAtt DiscountsInputTriggerLambda.Arn
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  CustomerEligibilityDataStorage:
    DependsOn: MDTLambdaInvokePermission
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub
        - 'cp-discounts-etl-customer-eligibility-data-storage-${env}'
        - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
      NotificationConfiguration:
        LambdaConfigurations:
          - Event: s3:ObjectCreated:*
            Function: !GetAtt DiscountsInputTriggerLambda.Arn
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  SoftOrHardValidationCE:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/CE/VALIDATION_TYPE' ] ]
      Type: String
      Value: !Ref ValidationTypeCE
      Tier: Standard
      Description: validation type for each attribute in CE flow

  SoftOrHardValidationMDT:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/MDT/VALIDATION_TYPE' ] ]
      Type: String
      Value: !Ref ValidationTypeMDT
      Tier: Standard
      Description: validation type for each attribute in MDT flow

  DiscountNameList:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/DISCOUNT_NAME_LIST' ] ]
      Type: String
      Value: !Ref ListOfDiscounts
      Tier: Standard
      Description: discount names allowed

  MDTAllowedColumnNameList:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/MDT/ALLOWED_COLUMN_NAMES_IN_ORDER' ] ]
      Type: String
      Value: !Ref AllowedColumnsMDT
      Tier: Standard
      Description: mdt column names allowed in the right order

  CommonDBEndpoint:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join ['', ['/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/COMMON/DB/ENDPOINT']]
      Type: String
      Value: !Ref CommonDBEndpointName
      Tier: Standard
      Description: Common db endpoint of discount service

  ActiveClusters:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join ['', ['/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ACTIVE/CLUSTERS']]
      Type: String
      Value: !Ref ActiveDBClusters
      Tier: Standard
      Description: Active clusters of discount service

  DiscountETLMaximumConcurrency:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join ['', ['/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/MAX_CONCURRENCY']]
      Type: String
      Value: !Ref ETLMaximumConcurrency
      Tier: Standard
      Description: Maximum Concurrency allowed for Discount ETL

  DiscountETLMaximumConcurrencyForCluster01:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/CE/LOAD_JOB/CLUSTER_01/MAX_CONCURRENCY' ] ]
      Type: String
      Value: !Ref CELoadJobMaximumConcurrencyForCluster01
      Tier: Standard
      Description: Maximum number of load job count allowed for cluster 01

  DiscountETLMaximumConcurrencyForCluster02:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/CE/LOAD_JOB/CLUSTER_02/MAX_CONCURRENCY' ] ]
      Type: String
      Value: !Ref CELoadJobMaximumConcurrencyForCluster02
      Tier: Standard
      Description: Maximum number of load job count allowed for cluster 02

  CEPartialLoadFileSizeUpperBound:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/CE/PARTIAL_LOAD_FILE_SIZE_UPPER_BOUND' ] ]
      Type: String
      Value: !Ref PartialLoadFileSizeUpperBound
      Tier: Standard
      Description: Upper bound value of customer eligibility partial load file size in GB

  PartitionGlueJobWorkerType:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join ['', ['/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/WORKER_TYPE']]
      Type: String
      Value: !Ref PartitionJobWorkerType
      Tier: Standard
      Description: Worker type for the ETL Partition Job

  PartitionGlueJobWorkerCountMin:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/WORKER_COUNT/MIN' ] ]
      Type: String
      Value: !Ref PartitionJobWorkerCountMin
      Tier: Standard
      Description: Minimum worker count for the ETL Partition Job

  PartitionGlueJobWorkerCountMax:
    Type: AWS::SSM::Parameter
    Properties:
      Name: !Join [ '', [ '/CP/DISCOUNT_SERVICE/', !Ref EnvironmentShort, '/ETL/WORKER_COUNT/MAX' ] ]
      Type: String
      Value: !Ref PartitionJobWorkerCountMax
      Tier: Standard
      Description: Maximum worker count for the ETL Partition Job

  CELambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !GetAtt DiscountsInputTriggerLambda.Arn
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub
        - 'arn:aws:s3:::cp-discounts-etl-customer-eligibility-data-storage-${env}'
        - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}

  MDTLambdaInvokePermission:
    Type: AWS::Lambda::Permission
    Properties:
      Action: lambda:InvokeFunction
      FunctionName: !GetAtt DiscountsInputTriggerLambda.Arn
      Principal: s3.amazonaws.com
      SourceAccount: !Ref 'AWS::AccountId'
      SourceArn: !Sub
        - 'arn:aws:s3:::cp-discounts-etl-mdt-data-storage-${env}'
        - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}

  DiscountsInputTriggerLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function that listens to pa data file uploads and triggers the step function
      FunctionName: !Sub 'CP-DISCOUNTS-etl-trigger-${EnvironmentShort}'
      Runtime: python3.7
      Role: !GetAtt ETLTriggerLambaRole.Arn
      Handler: TriggerLambda.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/TriggerLambda.py.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Timeout: 180
      Environment:
        Variables:
          stepFunctionArn: !Ref DiscountsStateMachine
          env: !Ref EnvironmentShort
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  DatabaseConnectionCluster01:
    Type: AWS::Glue::Connection
    Properties:
      CatalogId: !Ref AWS::AccountId
      ConnectionInput:
        ConnectionProperties: {
          "JDBC_CONNECTION_URL": !Join ['', ["jdbc:mysql://", "{{resolve:ssm:/CP/DISCOUNT_SERVICE/", !Ref EnvironmentShort, "/CLUSTER01/DISCOUNT/DB/ENDPOINT/WRITER:1}}", ":3306/mysql"]],
          "USERNAME": !Join ['', ["{{resolve:ssm:/CP/DISCOUNT_SERVICE/", !Ref EnvironmentShort, "/DISCOUNT/DB/USERNAME:1}}"]],
          # SSM Secure reference is not supported in: [AWS::glue::Connection]
          "PASSWORD": !Ref DatabasePassword
        }
        Description: Glue Connection to Referrence pricing database
        ConnectionType: JDBC
        Name: !Sub 'cp-DISCOUNTS-etl-connection-${EnvironmentShort}-cluster-01'
        PhysicalConnectionRequirements:
          AvailabilityZone: !Ref AvailabilityZoneForGlueConnection
          SecurityGroupIdList: !Ref SecurityGroupListForGlueConnction
          SubnetId: !Ref SubnetIdForGlueConnection

  DatabaseConnectionCluster02:
    Type: AWS::Glue::Connection
    Properties:
      CatalogId: !Ref AWS::AccountId
      ConnectionInput:
        ConnectionProperties: {
          "JDBC_CONNECTION_URL": !Join ['', ["jdbc:mysql://", "{{resolve:ssm:/CP/DISCOUNT_SERVICE/", !Ref EnvironmentShort, "/CLUSTER0", !If [twoClustersEnabled, "2", "1"], "/DISCOUNT/DB/ENDPOINT/WRITER:1}}", ":3306/mysql"]],
          "USERNAME": !Join [ '', [ "{{resolve:ssm:/CP/DISCOUNT_SERVICE/", !Ref EnvironmentShort, "/DISCOUNT/DB/USERNAME:1}}" ] ],
          # SSM Secure reference is not supported in: [AWS::glue::Connection]
          "PASSWORD": !Ref DatabasePassword
        }
        Description: Glue Connection to Referrence pricing database
        ConnectionType: JDBC
        Name: !Sub 'cp-DISCOUNTS-etl-connection-${EnvironmentShort}-cluster-02'
        PhysicalConnectionRequirements:
          AvailabilityZone: !Ref AvailabilityZoneForGlueConnection
          SecurityGroupIdList: !Ref SecurityGroupListForGlueConnction
          SubnetId: !Ref SubnetIdForGlueConnection

  CustomerEligibilityDataLoadJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/customer_eligibility.py"
      Connections:
        Connections:
          - !Ref DatabaseConnectionCluster01
          - !Ref DatabaseConnectionCluster02
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--extra-py-files": "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/PyMySQL-0.9.3-py2.py3-none-any.whl"
        "--GLUE_CONNECTION_NAME": !Ref GlueConnectionNamePlaceholder
        "--INTERMEDIATE_S3_BUCKET": !Ref IntermediateStorage
        "--ENV": !Ref EnvironmentShort
        "--METADATA_LAMBDA": !Sub 'CP-DISCOUNTS-etl-metadata-aggregator-${EnvironmentShort}'
      ExecutionProperty:
        MaxConcurrentRuns: !Ref CELoadJobMaximumConcurrency
      GlueVersion: 1.0
      MaxRetries: 0
      MaxCapacity: 1.0
      Timeout: 4320
      Name: !Sub 'CP-DISCOUNTS-etl-customer-eligibility-load-job-${EnvironmentShort}'
      Role: !Ref ETLGlueRole
      Tags: {
        'Technical:ApplicationName': !Ref ApplicationName,
        'Technical:ApplicationID': !Ref ApplicationID,
        'Technical:PlatformOwner': !Ref Owner,
        'Technical:Environment': !FindInMap [ EnvMap, !Ref EnvironmentShort, name ],
        'Support_Email': !Ref SupportEmail,
        'Approver': !Ref Approver,
        'PO_Number': !Ref PONumber,
        'Project_ID': !Ref ProjectID,
        '2WTAGGER': !Ref 2WTAGGER,
        'Platform': !Ref Platform,
        'Component': !Ref Component
      }

  MasterDiscountTableDataLoadJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/mdt.py"
      Connections:
        Connections:
          - !Ref DatabaseConnectionCluster01
          - !Ref DatabaseConnectionCluster02
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--extra-py-files": !Sub "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/PyMySQL-0.9.3-py2.py3-none-any.whl,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/jsonschema-3.2.0-py2.py3-none-any.whl,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/validator.py,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/constants.py,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/pyspark-2.4.3-py3-none-any.whl,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/py4j-0.10.7-py3-none-any.whl"
        "--GLUE_CONNECTION_NAME": !Ref GlueConnectionNamePlaceholder
        "--INTERMEDIATE_S3_BUCKET": !Ref IntermediateStorage
        "--ENV": !Ref EnvironmentShort
        "--METADATA_LAMBDA": !Sub 'CP-DISCOUNTS-etl-metadata-aggregator-${EnvironmentShort}'
      ExecutionProperty:
        MaxConcurrentRuns: !Ref ETLMaximumConcurrency
      GlueVersion: 1.0
      MaxRetries: 0
      MaxCapacity: 1.0
      Timeout: 4320
      Name: !Sub 'CP-DISCOUNTS-etl-mdt-load-job-${EnvironmentShort}'
      Role: !Ref ETLGlueRole
      Tags: {
        'Technical:ApplicationName': !Ref ApplicationName,
        'Technical:ApplicationID': !Ref ApplicationID,
        'Technical:PlatformOwner': !Ref Owner,
        'Technical:Environment': !FindInMap [ EnvMap, !Ref EnvironmentShort, name ],
        'Support_Email': !Ref SupportEmail,
        'Approver': !Ref Approver,
        'PO_Number': !Ref PONumber,
        'Project_ID': !Ref ProjectID,
        '2WTAGGER': !Ref 2WTAGGER,
        'Platform': !Ref Platform,
        'Component': !Ref Component
      }

  DiscountsStateMachine:
    Type: AWS::StepFunctions::StateMachine
    Properties:
      StateMachineName: !Sub 'CP-DISCOUNTS-state-machine-${EnvironmentShort}'
      StateMachineType: STANDARD
      DefinitionString: !Sub
        - |-
          {
            "Comment": "Transform and Loads PV and CE data from S3 to DB",
            "StartAt": "AnalyzeWaitStatus",
            "States": {
              "AnalyzeWaitStatus": {
                "Type": "Task",
                "Resource": "arn:aws:states:::lambda:invoke",
                "Parameters": {
                  "FunctionName": "${AnalyzeWaitExecutionLambdaArn}",
                  "Payload": {
                    "env.$": "$.ENV",
                    "etl_timestamp.$": "$.etl_timestamp",
                    "s3_object_key.$": "$.s3_object_key",
                    "file_type.$": "$.file_type",
                    "stepFunctionExecutionId.$": "$$.Execution.Id",
                    "stepFunctionArn.$": "$$.StateMachine.Id"
                  }
                },
                "ResultPath": "$.waitStatus",
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "Next": "WaitOrContinue"
              },
              "WaitOrContinue": {
                "Comment": "Check on wait status and wait or continue ETL",
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.waitStatus.Payload.shouldWait",
                    "BooleanEquals": true,
                    "Next": "waitExecution"
                  }
                ],
                "Default": "ChoiceState"
              },
              "waitExecution": {
                "Type": "Wait",
                "Seconds": 300,
                "Next": "AnalyzeWaitStatus"
              },
              "ChoiceState": {
                "Type": "Choice",
                "Choices": [
                  {
                    "Variable": "$.s3_bucket",
                    "StringMatches": "cp-discounts-etl-mdt-data-storage*",
                    "Next": "MDT ETL Job"
                  }
                ],
                "Default": "CE Decompress Job"
              },
              "MDT ETL Job": {
                "Type": "Task",
                "Resource": "arn:aws:states:::glue:startJobRun.sync",
                "Parameters": {
                  "JobName": "${MasterDiscountTableDataLoadJob}",
                  "Arguments": {
                    "--s3_file_path.$": "$.s3_file_path",
                    "--etl_timestamp.$": "$.etl_timestamp",
                    "--active_opcos.$": "$.active_opcos",
                    "--validation_type.$": "$.validation_type",
                    "--discount_names.$": "$.discount_names",
                    "--mdt_column_names_in_order.$": "$.mdt_column_names_in_order",
                    "--active_clusters.$": "$.active_clusters",
                    "--cluster_n_opcos_key.$": "$.cluster_n_opcos_key"
                  }
                },
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "ResultPath": "$.loadJob",
                "Next": "Clean and backup Job"
              },
              "CE Decompress Job": {
                "Type": "Task",
                "Resource": "arn:aws:states:::glue:startJobRun.sync",
                "Parameters": {
                  "JobName": "${CustomerEligibilityDecompressionJob}",
                  "Arguments": {
                    "--s3_file_path.$": "$.s3_file_path",
                    "--etl_timestamp.$": "$.etl_timestamp"
                  }
                },
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "ResultPath": "$.loadJob",
                "Next": "CE Partition Job"
              },
              "CE Partition Job": {
                "Type": "Task",
                "Resource": "arn:aws:states:::glue:startJobRun.sync",
                "Parameters": {
                  "JobName": "${CustomerEligibilityPartitionJob}",
                  "Arguments": {
                    "--s3_file_path.$": "$.s3_file_path",
                    "--etl_timestamp.$": "$.etl_timestamp",
                    "--active_opcos.$": "$.active_opcos",
                    "--validation_type_ce.$": "$.validation_type_ce"
                  },
                  "NumberOfWorkers.$": "$.worker_count",
                  "WorkerType.$": "$.worker_type"
                },
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "ResultPath": "$.loadJob",
                "Next": "FetchFileList"
              },
              "FetchFileList": {
                "Type": "Task",
                "Resource": "arn:aws:states:::lambda:invoke",
                "Parameters": {
                  "FunctionName": "${FetchFileListLambdaArn}",
                  "Payload": {
                    "etl_timestamp.$": "$.etl_timestamp",
                    "s3_object_key.$": "$.s3_object_key",
                    "cluster_n_opcos_key.$": "$.cluster_n_opcos_key",
                    "active_clusters.$": "$.active_clusters",
                    "ENV.$": "$.ENV"
                  }
                },
                "ResultPath": "$.opcoList",
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "Next": "LoadIntoClusters"
              },
              "LoadIntoClusters": {
                "Type": "Parallel",
                "End": true,
                "Branches": [
                  {
                    "StartAt": "AnalyseWaitOrLoadStatusC1",
                    "States": {
                      "AnalyseWaitOrLoadStatusC1": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${AnalyzeWaitLoadOrTerminateLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "cluster_n_opcos_key.$": "$.cluster_n_opcos_key",
                            "cluster": "01",
                            "opcos_cluster_01.$": "$.opcoList.Payload.opcos_cluster_01",
                            "ENV.$": "$.ENV"
                          }
                        },
                        "ResultPath": "$.decision",
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC1"
                          }
                        ],
                        "Next": "WaitLoadOrTerminateC1"
                      },
                      "WaitLoadOrTerminateC1": {
                        "Type": "Choice",
                        "Choices": [
                          {
                            "Variable": "$.decision.Payload.nextStep",
                            "StringEquals": "wait",
                            "Next": "WaitLoadingC1"
                          },
                          {
                            "Variable": "$.decision.Payload.nextStep",
                            "StringEquals": "load",
                            "Next": "LoadAllC1"
                          }
                        ],
                        "Default": "TerminateC1"
                      },
                      "TerminateC1": {
                        "Type": "Succeed"
                      },
                      "WaitLoadingC1": {
                        "Type": "Wait",
                        "Seconds": 300,
                        "Next": "AnalyseWaitOrLoadStatusC1"
                      },
                      "LoadAllC1": {
                        "Type": "Map",
                        "ItemsPath": "$.opcoList.Payload.opcos_cluster_01",
                        "MaxConcurrency": ${LoadJobMaximumConcurrencyCluster01},
                        "Parameters": {
                          "id.$": "$$.Map.Item.Value",
                          "s3_file_path.$": "$.s3_file_path",
                          "etl_timestamp.$": "$.etl_timestamp",
                          "active_opcos.$": "$.active_opcos",
                          "workflow_file_dir.$": "$.workflow_file_dir",
                          "file_type.$": "$.file_type",
                          "s3_object_key.$": "$.s3_object_key"
                        },
                        "Iterator": {
                          "StartAt": "LoadJobC1",
                          "States": {
                            "LoadJobC1": {
                              "Type": "Task",
                              "Resource": "arn:aws:states:::glue:startJobRun.sync",
                              "Parameters": {
                                "JobName": "${CustomerEligibilityDataLoadJob}",
                                "Arguments": {
                                  "--cluster": "01",
                                  "--opco_id.$": "$.id",
                                  "--s3_file_path.$": "$.s3_file_path",
                                  "--etl_timestamp.$": "$.etl_timestamp",
                                  "--active_opcos.$": "$.active_opcos",
                                  "--workflow_file_dir.$": "$.workflow_file_dir"
                                }
                              },
                              "Retry": [
                                {
                                  "ErrorEquals": [
                                    "States.TaskFailed"
                                  ],
                                  "IntervalSeconds": 3,
                                  "MaxAttempts": 2,
                                  "BackoffRate": 10
                                }
                              ],
                              "Catch": [
                                {
                                  "ErrorEquals": [
                                    "States.TaskFailed"
                                  ],
                                  "ResultPath": "$.error",
                                  "Next": "NotifyLoadJobFailureC1"
                                }
                              ],
                              "ResultPath": "$.loadJob",
                              "End": true
                            },
                            "NotifyLoadJobFailureC1": {
                              "Type": "Task",
                              "Resource": "arn:aws:states:::lambda:invoke",
                              "Parameters": {
                                "FunctionName": "${notifierLambdaArn}",
                                "Payload": {
                                  "event": "[ETL] - [Discount Service]",
                                  "etl_timestamp.$": "$.etl_timestamp",
                                  "s3_object_key.$": "$.s3_object_key",
                                  "additional_info_bucket_name": "${IntermediateBucketName}",
                                  "additional_info_file_dir.$": "$.workflow_file_dir",
                                  "file_type.$": "$.file_type",
                                  "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}, Error: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id, $.error.Cause)"
                                }
                              },
                              "End": true
                            }
                          }
                        },
                        "ResultPath": "$.clusterloadJobResult",
                        "Next": "TakeBackupDecisionC1"
                      },
                      "TakeBackupDecisionC1": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${TakeBackpDecisionLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "ENV.$": "$.ENV",
                            "s3_object_key.$": "$.s3_object_key",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "cluster_n_opcos_key.$": "$.cluster_n_opcos_key",
                            "opcos_cluster_01.$": "$.opcoList.Payload.opcos_cluster_01",
                            "allocated_job_count.$": "$.decision.Payload.allocatedJobCount",
                            "load_job_statuses.$": "$.clusterloadJobResult",
                            "cluster": "01"
                          }
                        },
                        "Retry": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "IntervalSeconds": 3,
                            "MaxAttempts": 2,
                            "BackoffRate": 10
                          }
                        ],
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC1"
                          }
                        ],
                        "ResultPath": "$.backupDecision",
                        "Next": "BackupOrNotC1"
                      },
                      "BackupOrNotC1": {
                        "Type": "Choice",
                        "Choices": [
                          {
                            "Variable": "$.backupDecision.Payload.shouldBackup",
                            "BooleanEquals": true,
                            "Next": "BackupC1"
                          }
                        ],
                        "Default": "SkipBackupC1"
                      },
                      "SkipBackupC1": {
                        "Type": "Succeed"
                      },
                      "BackupC1": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::glue:startJobRun.sync",
                        "Parameters": {
                          "JobName": "${DiscountDataBackupJob}",
                          "Arguments": {
                            "--s3_file_path.$": "$.s3_file_path",
                            "--s3_bucket.$": "$.s3_bucket",
                            "--s3_object_key.$": "$.s3_object_key",
                            "--etl_timestamp.$": "$.etl_timestamp",
                            "--backup_file_path.$": "$.workflow_file_dir"
                          }
                        },
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC1"
                          }
                        ],
                        "ResultPath": "$.backupJob",
                        "Next": "NotifySuccessC1"
                      },
                      "NotifyFailureC1": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${notifierLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "additional_info_bucket_name": "${IntermediateBucketName}",
                            "additional_info_file_dir.$": "$.workflow_file_dir",
                            "file_type.$": "$.file_type",
                            "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}, Error: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id, $.error.Cause)"
                          }
                        },
                        "End": true
                      },
                      "NotifySuccessC1": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${notifierLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "additional_info_bucket_name": "${ETLDataBackUpStorage}",
                            "additional_info_file_dir.$": "$.workflow_file_dir",
                            "file_type.$": "$.file_type",
                            "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id)",
                            "status": "SUCCEEDED"
                          }
                        },
                        "End": true
                      }
                    }
                  },
                  {
                    "StartAt": "AnalyseWaitOrLoadStatusC2",
                    "States": {
                      "AnalyseWaitOrLoadStatusC2": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${AnalyzeWaitLoadOrTerminateLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "cluster_n_opcos_key.$": "$.cluster_n_opcos_key",
                            "cluster": "02",
                            "opcos_cluster_02.$": "$.opcoList.Payload.opcos_cluster_02",
                            "ENV.$": "$.ENV"
                          }
                        },
                        "ResultPath": "$.decision",
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC2"
                          }
                        ],
                        "Next": "WaitLoadOrTerminateC2"
                      },
                      "WaitLoadOrTerminateC2": {
                        "Type": "Choice",
                        "Choices": [
                          {
                            "Variable": "$.decision.Payload.nextStep",
                            "StringEquals": "wait",
                            "Next": "WaitLoadingC2"
                          },
                          {
                            "Variable": "$.decision.Payload.nextStep",
                            "StringEquals": "load",
                            "Next": "LoadAllC2"
                          }
                        ],
                        "Default": "TerminateC2"
                      },
                      "TerminateC2": {
                        "Type": "Succeed"
                      },
                      "WaitLoadingC2": {
                        "Type": "Wait",
                        "Seconds": 300,
                        "Next": "AnalyseWaitOrLoadStatusC2"
                      },
                      "LoadAllC2": {
                        "Type": "Map",
                        "ItemsPath": "$.opcoList.Payload.opcos_cluster_02",
                        "MaxConcurrency": ${LoadJobMaximumConcurrencyCluster02},
                        "Parameters": {
                          "id.$": "$$.Map.Item.Value",
                          "s3_file_path.$": "$.s3_file_path",
                          "etl_timestamp.$": "$.etl_timestamp",
                          "active_opcos.$": "$.active_opcos",
                          "workflow_file_dir.$": "$.workflow_file_dir",
                          "file_type.$": "$.file_type",
                          "s3_object_key.$": "$.s3_object_key"
                        },
                        "Iterator": {
                          "StartAt": "LoadJobC2",
                          "States": {
                            "LoadJobC2": {
                              "Type": "Task",
                              "Resource": "arn:aws:states:::glue:startJobRun.sync",
                              "Parameters": {
                                "JobName": "${CustomerEligibilityDataLoadJob}",
                                "Arguments": {
                                  "--cluster": "02",
                                  "--opco_id.$": "$.id",
                                  "--s3_file_path.$": "$.s3_file_path",
                                  "--etl_timestamp.$": "$.etl_timestamp",
                                  "--active_opcos.$": "$.active_opcos",
                                  "--workflow_file_dir.$": "$.workflow_file_dir"
                                }
                              },
                              "Retry": [
                                {
                                  "ErrorEquals": [
                                    "States.TaskFailed"
                                  ],
                                  "IntervalSeconds": 3,
                                  "MaxAttempts": 2,
                                  "BackoffRate": 10
                                }
                              ],
                              "Catch": [
                                {
                                  "ErrorEquals": [
                                    "States.TaskFailed"
                                  ],
                                  "ResultPath": "$.error",
                                  "Next": "NotifyLoadJobFailureC2"
                                }
                              ],
                              "ResultPath": "$.loadJob",
                              "End": true
                            },
                            "NotifyLoadJobFailureC2": {
                              "Type": "Task",
                              "Resource": "arn:aws:states:::lambda:invoke",
                              "Parameters": {
                                "FunctionName": "${notifierLambdaArn}",
                                "Payload": {
                                  "event": "[ETL] - [Discount Service]",
                                  "etl_timestamp.$": "$.etl_timestamp",
                                  "s3_object_key.$": "$.s3_object_key",
                                  "additional_info_bucket_name": "${IntermediateBucketName}",
                                  "additional_info_file_dir.$": "$.workflow_file_dir",
                                  "file_type.$": "$.file_type",
                                  "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}, Error: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id, $.error.Cause)"
                                }
                              },
                              "End": true
                            }
                          }
                        },
                        "ResultPath": "$.clusterloadJobResult",
                        "Next": "TakeBackupDecisionC2"
                      },
                      "TakeBackupDecisionC2": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${TakeBackpDecisionLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "ENV.$": "$.ENV",
                            "s3_object_key.$": "$.s3_object_key",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "cluster_n_opcos_key.$": "$.cluster_n_opcos_key",
                            "opcos_cluster_02.$": "$.opcoList.Payload.opcos_cluster_02",
                            "allocated_job_count.$": "$.decision.Payload.allocatedJobCount",
                            "load_job_statuses.$": "$.clusterloadJobResult",
                            "cluster": "02"
                          }
                        },
                        "Retry": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "IntervalSeconds": 3,
                            "MaxAttempts": 2,
                            "BackoffRate": 10
                          }
                        ],
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC2"
                          }
                        ],
                        "ResultPath": "$.backupDecision",
                        "Next": "BackupOrNotC2"
                      },
                      "BackupOrNotC2": {
                        "Type": "Choice",
                        "Choices": [
                          {
                            "Variable": "$.backupDecision.Payload.shouldBackup",
                            "BooleanEquals": true,
                            "Next": "BackupC2"
                          }
                        ],
                        "Default": "SkipBackupC2"
                      },
                      "SkipBackupC2": {
                        "Type": "Succeed"
                      },
                      "BackupC2": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::glue:startJobRun.sync",
                        "Parameters": {
                          "JobName": "${DiscountDataBackupJob}",
                          "Arguments": {
                            "--s3_file_path.$": "$.s3_file_path",
                            "--s3_bucket.$": "$.s3_bucket",
                            "--s3_object_key.$": "$.s3_object_key",
                            "--etl_timestamp.$": "$.etl_timestamp",
                            "--backup_file_path.$": "$.workflow_file_dir"
                          }
                        },
                        "Catch": [
                          {
                            "ErrorEquals": [
                              "States.TaskFailed"
                            ],
                            "ResultPath": "$.error",
                            "Next": "NotifyFailureC2"
                          }
                        ],
                        "ResultPath": "$.backupJob",
                        "Next": "NotifySuccessC2"
                      },
                      "NotifyFailureC2": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${notifierLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "additional_info_bucket_name": "${IntermediateBucketName}",
                            "additional_info_file_dir.$": "$.workflow_file_dir",
                            "file_type.$": "$.file_type",
                            "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}, Error: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id, $.error.Cause)"
                          }
                        },
                        "End": true
                      },
                      "NotifySuccessC2": {
                        "Type": "Task",
                        "Resource": "arn:aws:states:::lambda:invoke",
                        "Parameters": {
                          "FunctionName": "${notifierLambdaArn}",
                          "Payload": {
                            "event": "[ETL] - [Discount Service]",
                            "etl_timestamp.$": "$.etl_timestamp",
                            "s3_object_key.$": "$.s3_object_key",
                            "additional_info_bucket_name": "${ETLDataBackUpStorage}",
                            "additional_info_file_dir.$": "$.workflow_file_dir",
                            "file_type.$": "$.file_type",
                            "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id)",
                            "status": "SUCCEEDED"
                          }
                        },
                        "End": true
                      }
                    }
                  }
                ]
              },
              "Clean and backup Job": {
                "Type": "Task",
                "Resource": "arn:aws:states:::glue:startJobRun.sync",
                "Parameters": {
                  "JobName": "${DiscountDataBackupJob}",
                  "Arguments": {
                    "--s3_file_path.$": "$.s3_file_path",
                    "--s3_bucket.$": "$.s3_bucket",
                    "--s3_object_key.$": "$.s3_object_key",
                    "--etl_timestamp.$": "$.etl_timestamp",
                    "--backup_file_path.$": "$.workflow_file_dir"
                  }
                },
                "Catch": [
                  {
                    "ErrorEquals": [
                      "States.TaskFailed"
                    ],
                    "ResultPath": "$.error",
                    "Next": "Notify ETL Failure"
                  }
                ],
                "ResultPath": "$.backupJob",
                "Next": "Notify ETL Success"
              },
              "Notify ETL Failure": {
                "Type": "Task",
                "Resource": "arn:aws:states:::lambda:invoke",
                "Parameters": {
                  "FunctionName": "${notifierLambdaArn}",
                  "Payload": {
                    "event": "[ETL] - [Discount Service]",
                    "etl_timestamp.$": "$.etl_timestamp",
                    "s3_object_key.$": "$.s3_object_key",
                    "additional_info_bucket_name": "${IntermediateBucketName}",
                    "additional_info_file_dir.$": "$.workflow_file_dir",
                    "file_type.$": "$.file_type",
                    "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}, Error: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id, $.error.Cause)"
                  }
                },
                "End": true
              },
              "Notify ETL Success": {
                "Type": "Task",
                "Resource": "arn:aws:states:::lambda:invoke",
                "Parameters": {
                  "FunctionName": "${notifierLambdaArn}",
                  "Payload": {
                    "event": "[ETL] - [Discount Service]",
                    "etl_timestamp.$": "$.etl_timestamp",
                    "s3_object_key.$": "$.s3_object_key",
                    "additional_info_bucket_name": "${ETLDataBackUpStorage}",
                    "additional_info_file_dir.$": "$.workflow_file_dir",
                    "file_type.$": "$.file_type",
                    "message.$": "States.Format('S3 Path: {}, ETL timestamp: {}, Execution Id: {}', $.s3_file_path, $.etl_timestamp, $$.Execution.Id)",
                    "status": "SUCCEEDED"
                  }
                },
                "End": true
              }
            }
          }
        - {
          MasterDiscountTableDataLoadJob: !Ref MasterDiscountTableDataLoadJob,
          notifierLambdaArn: !GetAtt NotifierLambda.Arn,
          AnalyzeWaitExecutionLambdaArn: !GetAtt AnalyzeWaitExecutionLambda.Arn,
          FetchFileListLambdaArn: !GetAtt FetchFileListLambda.Arn,
          TakeBackpDecisionLambdaArn: !GetAtt TakeBackpDecisionLambda.Arn,
          AnalyzeWaitLoadOrTerminateLambdaArn: !GetAtt AnalyzeWaitLoadOrTerminateLambda.Arn,
          CustomerEligibilityDataLoadJob: !Ref CustomerEligibilityDataLoadJob,
          DiscountDataBackupJob: !Ref DiscountDataBackupJob,
          CustomerEligibilityDecompressionJob: !Ref CustomerEligibilityDecompressionJob,
          CustomerEligibilityPartitionJob: !Ref CustomerEligibilityPartitionJob,
          IntermediateBucketName: !Ref IntermediateStorage,
          ETLDataBackUpStorage: !Ref ETLDataBackUpStorage,
          LoadJobMaximumConcurrencyCluster01: !Ref CELoadJobMaximumConcurrencyForCluster01,
          LoadJobMaximumConcurrencyCluster02: !Ref CELoadJobMaximumConcurrencyForCluster02
        }
      LoggingConfiguration:
        Destinations:
          - CloudWatchLogsLogGroup:
              LogGroupArn: !GetAtt PAStepFunctionExecutionLogs.Arn
        IncludeExecutionData: TRUE
        Level: ALL
      RoleArn: !GetAtt ETLStepFunctionExecutionRole.Arn
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  PAStepFunctionExecutionLogs:
    Type: AWS::Logs::LogGroup
    Properties:
      LogGroupName: !Sub 'cp-discounts-etl-mdt-step-function-logs-${EnvironmentShort}'
      RetentionInDays: 30

  ETLGlueRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'CP-DISCOUNTS-ETLGlueRole-${EnvironmentShort}'
      PermissionsBoundary: !Sub 'arn:aws:iam::${AWS::AccountId}:policy/PermissionBoundary-DevOps'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - 'glue.amazonaws.com'
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
        - arn:aws:iam::aws:policy/service-role/AWSLambdaRole
        - !Sub 'arn:aws:iam::${AWS::AccountId}:policy/CloudPricing-IAM-SSM-Policy'
      Policies:
        - PolicyName: CP-REF-ETLGlueJobPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:CreateLogGroup
                  - logs:PutLogEvents
                  - logs:AssociateKmsKey
                Resource: 'arn:aws:logs:*:*:/aws-glue/*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - 'arn:aws:s3:::sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}'
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource: !Sub
                  - 'arn:aws:s3:::cp-discounts-etl-mdt-data-storage-${env}/*'
                  - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource: !Sub
                  - 'arn:aws:s3:::cp-discounts-etl-customer-eligibility-data-storage-${env}/*'
                  - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource: !Sub
                  - 'arn:aws:s3:::cp-ref-etl-prize-zone-spark-temp-dir-${env}/*'
                  - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
      Path: '/'

  DiscountDataBackupJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub 's3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/data_backup_job.py'
      DefaultArguments:
        "--INTERMEDIATE_S3_BUCKET": !Ref IntermediateStorage
        "--ARCHIVING_S3_BUCKET": !Ref ETLDataBackUpStorage
      ExecutionProperty:
        MaxConcurrentRuns: 10
      GlueVersion: 1.0
      MaxRetries: 0
      MaxCapacity: 1.0
      Name: !Sub 'CP-DISCOUNTS-etl-backup-job-${EnvironmentShort}'
      Role: !Ref ETLDataBackUpGlueRole
      Tags: {
        'Technical:ApplicationName': !Ref ApplicationName,
        'Technical:ApplicationID': !Ref ApplicationID,
        'Technical:PlatformOwner': !Ref Owner,
        'Technical:Environment': !FindInMap [ EnvMap, !Ref EnvironmentShort, name ],
        'Support_Email': !Ref SupportEmail,
        'Approver': !Ref Approver,
        'PO_Number': !Ref PONumber,
        'Project_ID': !Ref ProjectID,
        '2WTAGGER': !Ref 2WTAGGER,
        'Platform': !Ref Platform,
        'Component': !Ref Component
      }

  ETLDataBackUpGlueRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'CP-DISCOUNTS-ETLDataBackupGlueRole-${EnvironmentShort}'
      PermissionsBoundary: !Sub 'arn:aws:iam::${AWS::AccountId}:policy/PermissionBoundary-DevOps'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - 'glue.amazonaws.com'
            Action:
              - 'sts:AssumeRole'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole
      Policies:
        - PolicyName: CP-DISCOUNTS-ETLDataBackupGlueJobPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:CreateLogGroup
                  - logs:PutLogEvents
                  - logs:AssociateKmsKey
                Resource: 'arn:aws:logs:*:*:/aws-glue/*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                Resource:
                  - 'arn:aws:s3:::sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:DeleteObject
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}/*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:DeleteObject
                Resource: !Sub
                  - 'arn:aws:s3:::cp-discounts-etl-mdt-data-storage-${env}/*'
                  - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:DeleteObject
                Resource: !Sub
                  - 'arn:aws:s3:::cp-discounts-etl-customer-eligibility-data-storage-${env}/*'
                  - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${ETLDataBackUpStorage}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${ETLDataBackUpStorage}'
      Path: '/'

  ETLDataBackUpStorage:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub
        - 'cp-discounts-etl-data-backup-storage-${env}'
        - { env: !FindInMap [ EnvMap, !Ref EnvironmentShort, val ]}
      LifecycleConfiguration:
        Rules:
          - Transitions:
              - StorageClass: GLACIER
                TransitionInDays: 30
            Id: Transition-To-Glacier-Rule
            Status: Enabled
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  ETLTriggerLambaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'CP-DISCOUNTS-ETLTriggerLambdaRole-${EnvironmentShort}'
      PermissionsBoundary: !Sub 'arn:aws:iam::${AWS::AccountId}:policy/PermissionBoundary-DevOps'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
      Policies:
        - PolicyName: CP-REF-StartStepFunctionExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - states:StartExecution
                  - ec2:CreateNetworkInterface
                  - ec2:DescribeNetworkInterfaces
                  - ec2:DeleteNetworkInterface
                  - ec2:DescribeInstances
                  - ec2:AttachNetworkInterface
                  - ssm:GetParameters
                  - ssm:GetParameter
                Resource:
                  - '*'
        - PolicyName: cp-discounts-etl-s3-read-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:GetObjectVersion
                  - s3:DeleteObject
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${ETLDataBackUpStorage}/*'
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}/*'
        - PolicyName: !Sub 'cp-discounts-etl-s3-read-policy-${EnvironmentShort}'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:GetObjectVersion
                Resource:
                  - !Sub 'arn:aws:s3:::cp-discounts-etl-output-bucket-${EnvironmentShort}'
                  - !Sub 'arn:aws:s3:::cp-discounts-etl-output-bucket-${EnvironmentShort}/*'
      Path: '/'


  NotifierLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function that use CPNS to notify
      FunctionName: !Sub 'CP-DISCOUNTS-etl-notifier-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt ETLTriggerLambaRole.Arn
      Handler: index.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/Notifier.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Environment:
        Variables:
          env: !Ref EnvironmentShort
          cp_notification_url: !Ref NotificationURL
          cp_notification_host: !Ref NotificationHost
          teams_webhook_url: !Ref TeamsWebhookURL
      Timeout: 60
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  MetadataAggregatorLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function that collects metadata
      FunctionName: !Sub 'CP-DISCOUNTS-etl-metadata-aggregator-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt ETLTriggerLambaRole.Arn
      Handler: metadata_aggregator.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/metadata_aggregator.py.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Environment:
        Variables:
          env: !Ref EnvironmentShort
      Timeout: 60
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  ETLStepFunctionExecutionRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: !Sub 'CP-DISCOUNTS-ETLStepFunctionExecutionRole-${EnvironmentShort}'
      PermissionsBoundary: !Sub 'arn:aws:iam::${AWS::AccountId}:policy/PermissionBoundary-DevOps'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service:
                - !Sub 'states.${AWS::Region}.amazonaws.com'
            Action: 'sts:AssumeRole'
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaRole
      Policies:
        - PolicyName: CP-REF-ExecuteGlueJobPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - glue:GetJobs
                  - glue:BatchStopJobRun
                  - glue:ListJobs
                  - glue:CreateJob
                  - glue:BatchGetJobs
                  - glue:StartJobRun
                  - glue:GetJobRun
                  - glue:UpdateJob
                  - glue:GetJobRuns
                  - glue:GetJob
                Resource: "*"
        - PolicyName: LogStepFunctionEventPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:DescribeDestinations
                  - logs:PutDestination
                  - logs:CreateLogDelivery
                  - logs:GetLogDelivery
                  - logs:UpdateLogDelivery
                  - logs:DeleteLogDelivery
                  - logs:ListLogDeliveries
                  - logs:PutResourcePolicy
                  - logs:DescribeResourcePolicies
                  - logs:DescribeLogGroups
                Resource: '*'
      Path: '/'

  CustomerEligibilityDecompressionJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: pythonshell
        PythonVersion: 3
        ScriptLocation: !Sub 's3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/decompress_job.py'
      DefaultArguments:
        "--job-bookmark-option": "job-bookmark-disable"
        "--extra-py-files": !Sub "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/libraries/smart_open-2.1.0-py3.6.egg"
        "--INTERMEDIATE_S3_BUCKET": !Ref IntermediateStorage
      ExecutionProperty:
        MaxConcurrentRuns: !Ref ETLMaximumConcurrency
      GlueVersion: 1.0
      MaxRetries: 0
      MaxCapacity: 1.0
      Timeout: 4320
      Name: !Sub 'CP-DISCOUNTS-etl-customer-eligibility-decompress-job-${EnvironmentShort}'
      Role: !Ref ETLGlueRole
      Tags: {
        'Technical:ApplicationName': !Ref ApplicationName,
        'Technical:ApplicationID': !Ref ApplicationID,
        'Technical:PlatformOwner': !Ref Owner,
        'Technical:Environment': !FindInMap [ EnvMap, !Ref EnvironmentShort, name ],
        'Support_Email': !Ref SupportEmail,
        'Approver': !Ref Approver,
        'PO_Number': !Ref PONumber,
        'Project_ID': !Ref ProjectID,
        '2WTAGGER': !Ref 2WTAGGER,
        'Platform': !Ref Platform,
        'Component': !Ref Component
      }

  CustomerEligibilityPartitionJob:
    Type: AWS::Glue::Job
    Properties:
      Command:
        Name: glueetl
        PythonVersion: 3
        ScriptLocation: !Sub 's3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/customer_eligibility_partitioner.py'
      DefaultArguments:
        "--enable-metrics": ""
        "--enable-continuous-cloudwatch-log": "true"
        "--enable-continuous-log-filter": "true"
        "--enable-spark-ui": 'true'
        "--INTERMEDIATE_S3_BUCKET": !Ref IntermediateStorage
        "--ENV": !Ref EnvironmentShort
        "--METADATA_LAMBDA": !Sub 'CP-DISCOUNTS-etl-metadata-aggregator-${EnvironmentShort}'
        "--extra-py-files": !Sub "s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/validator.py,s3://sysco-us-east-1-prcp-nonprod-codedeploy/DiscountService/${EnvironmentShort}/constants.py"
      ExecutionProperty:
        MaxConcurrentRuns: !Ref ETLMaximumConcurrency
      GlueVersion: 2.0
      WorkerType: !Ref PartitionJobWorkerType
      NumberOfWorkers: !Ref PartitionJobWorkerCountMin
      MaxRetries: 0
      Name: !Sub 'CP-DISCOUNTS-etl-customer-eligibility-partition-job-${EnvironmentShort}'
      Role: !Ref ETLGlueRole
      Tags: {
        'Technical:ApplicationName': !Ref ApplicationName,
        'Technical:ApplicationID': !Ref ApplicationID,
        'Technical:PlatformOwner': !Ref Owner,
        'Technical:Environment': !FindInMap [ EnvMap, !Ref EnvironmentShort, name ],
        'Support_Email': !Ref SupportEmail,
        'Approver': !Ref Approver,
        'PO_Number': !Ref PONumber,
        'Project_ID': !Ref ProjectID,
        '2WTAGGER': !Ref 2WTAGGER,
        'Platform': !Ref Platform,
        'Component': !Ref Component
      }

  StepFunctionHelperLambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub 'CP-DISCOUNTS-StepFunctionHelperLambdaRole-${EnvironmentShort}'
      PermissionsBoundary: !Sub 'arn:aws:iam::${AWS::AccountId}:policy/PermissionBoundary-DevOps'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole
      Policies:
        - PolicyName: cp-discounts-etl-s3-access-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:ListBucket
                  - s3:GetObjectVersion
                  - s3:DeleteObject
                  - s3:PutObject
                Resource:
                  - !Sub 'arn:aws:s3:::${ETLDataBackUpStorage}/*'
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}/*'
              - Effect: Allow
                Action:
                  - s3:ListBucket
                Resource:
                  - !Sub 'arn:aws:s3:::${IntermediateStorage}'
        - PolicyName: cp-discounts-etl-step-function-access-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - states:ListExecutions
                  - states:StartExecution
                Resource:
                  - '*'
        - PolicyName: cp-discounts-etl-ssm-access-policy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ssm:GetParameter
                  - ssm:GetParameters
                Resource:
                  - '*'
      Path: '/'

  FetchFileListLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function for identifying OpCos contained in CE file and separte them into clusters
      FunctionName: !Sub 'CP-DISCOUNTS-etl-fetch-file-list-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt StepFunctionHelperLambdaRole.Arn
      Handler: index.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/FetchFileListLambda.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Environment:
        Variables:
          INTERMEDIATE_S3_BUCKET: !Ref IntermediateStorage
      Timeout: 180
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  AnalyzeWaitLoadOrTerminateLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function for deciding wait, load or teminate status of the load job for a cluster
      FunctionName: !Sub 'CP-DISCOUNTS-etl-analyze-wait-load-or-terminate-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt StepFunctionHelperLambdaRole.Arn
      Handler: index.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/AnalyzeWaitOrLoadClusterLambda.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Timeout: 180
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  TakeBackpDecisionLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function for taking bacup decision based on the load job statues
      FunctionName: !Sub 'CP-DISCOUNTS-etl-take-backup-decision-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt StepFunctionHelperLambdaRole.Arn
      Handler: index.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/TakeBackupDecisionLambda.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Timeout: 180
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component

  AnalyzeWaitExecutionLambda:
    Type: AWS::Lambda::Function
    Properties:
      Description: Lambda function for deciding step function execution
      FunctionName: !Sub 'CP-DISCOUNTS-etl-analyze-wait-execution-${EnvironmentShort}'
      Runtime: python3.8
      Role: !GetAtt StepFunctionHelperLambdaRole.Arn
      Handler: AnalyzeWaitExecutionLambda.lambda_handler
      Code:
        S3Bucket: sysco-us-east-1-prcp-nonprod-codedeploy
        S3Key: !Sub 'DiscountService/${EnvironmentShort}/AnalyzeWaitExecutionLambda.py.zip'
      VpcConfig:
        SecurityGroupIds:
          !Ref NotifierLambdaSecutyGroup
        SubnetIds:
          !Ref NotifierLambdaSubnets
      Timeout: 180
      Tags:
        - Key: Technical:ApplicationName
          Value: !Ref ApplicationName
        - Key: Technical:ApplicationID
          Value: !Ref ApplicationID
        - Key: Technical:PlatformOwner
          Value: !Ref Owner
        - Key: Technical:Environment
          Value: !FindInMap [ EnvMap, !Ref EnvironmentShort, name ]
        - Key: Support_Email
          Value: !Ref SupportEmail
        - Key: Approver
          Value: !Ref Approver
        - Key: PO_Number
          Value: !Ref PONumber
        - Key: Project_ID
          Value: !Ref ProjectID
        - Key: 2WTAGGER
          Value: !Ref 2WTAGGER
        - Key: Platform
          Value: !Ref Platform
        - Key: Component
          Value: !Ref Component
